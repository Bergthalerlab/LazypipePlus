Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 8
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	create_reports
	1	format_hsearch_main
	1	krona_graph
	1	pack
	1	sans_orfs
	1	summary_excel
	7

[Mon Aug  1 11:13:10 2022]
rule sans_orfs:
    input: results/sample2/ORFs.aa.fa
    output: results/sample2/dbhits.sans.tsv
    log: logs/sample2/sans_orfs.log
    jobid: 14
    wildcards: sample=sample2
    threads: 8

python3.10 SANSPANZ.3/runsanspanz.py -m SANStopHtaxid --SANS_H 5 -R  -i results/sample2/ORFs.aa.fa -o results/sample2/dbhits.sans.tsv &> logs/sample2/sans_orfs.log
[Mon Aug  1 11:13:10 2022]
Error in rule sans_orfs:
    jobid: 14
    output: results/sample2/dbhits.sans.tsv
    log: logs/sample2/sans_orfs.log (check log file(s) for error message)
    shell:
        python3.10 SANSPANZ.3/runsanspanz.py -m SANStopHtaxid --SANS_H 5 -R  -i results/sample2/ORFs.aa.fa -o results/sample2/dbhits.sans.tsv &> logs/sample2/sans_orfs.log
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/ptriska/Desktop/metagenomics/MPX_experiment/lazypipe/.snakemake/log/2022-08-01T111309.813673.snakemake.log
